services:
  rsshub:
    image: diygod/rsshub:latest
    restart: unless-stopped
    ports:
      - "1200:1200"
    environment:
      NODE_ENV: production
      CACHE_TYPE: redis
      REDIS_URL: "redis://redis:6379/"
      PUPPETEER_WS_ENDPOINT: "ws://browserless:3000"
      
      # 缓存配置 - 针对 Twitter 优化
      CACHE_EXPIRE: 1800        # 30分钟缓存
      CACHE_CONTENT_EXPIRE: 3600 # 1小时内容缓存
      
      # Twitter 认证 - 关键配置
      TWITTER_USERNAME: '${TWITTER_USERNAME}' # 使用环境变量
      TWITTER_PASSWORD: '${TWITTER_PASSWORD}' # 使用环境变量
    depends_on:
      - redis
      - browserless
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:1200/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5

  browserless:
    image: browserless/chrome:latest
    restart: unless-stopped

  redis:
    image: redis:alpine
    restart: unless-stopped
    volumes:
      - redis-data:/data

  tei:
    # 针对 ARM64 架构使用 CPU 版本
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.5
    platform: linux/amd64  # 使用 Rosetta 2 模拟
    restart: unless-stopped
    command: ["--model-id", "Qwen/Qwen3-Embedding-0.6B"]
    environment:
      HF_HUB_ENABLE_HF_TRANSFER: "1"
    ports:
      - "8080:80"
    volumes:
      - tei-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 5s
      retries: 10

  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 5s
      retries: 10

  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    restart: "no"
    depends_on:
      - rsshub
      - tei
      - ollama
    working_dir: /workspace
    volumes:
      - ./:/workspace
      - models-cache:/root/.cache/huggingface
      - logs:/workspace/logs
    env_file: .env
    command: ["sleep", "infinity"]

volumes:
  redis-data: {}
  tei-data: {}
  ollama: {}
  models-cache: {}
  logs: {}
